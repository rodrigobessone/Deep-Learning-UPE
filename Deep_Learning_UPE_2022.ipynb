{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u_w4ruhJcTNZ"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 120\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "sAzBc2QDcVgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a504fd-6972-4838-bd2b-38557ee84d66"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y39nL1HdccTp",
        "outputId": "d2ecbb01-7f84-444e-9107-8ad4bad4a281"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "tz9ZfpHxcfBI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "# prepare iterator\n",
        "it_train = datagen.flow(x_train, y_train, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "36-SwT6GL-Cw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    #EarlyStopping(monitor='loss', patience=3),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "]\n",
        "\n",
        "steps = int(x_train.shape[0] / batch_size)\n",
        "model.fit(it_train, steps_per_epoch=steps, epochs=epochs, validation_data=(x_test, y_test), verbose=1, callbacks=callbacks)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "l919knBmcjHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ca10b4-6407-4591-f835-2f17e64a3033"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "781/781 [==============================] - 49s 45ms/step - loss: 1.8298 - accuracy: 0.4029 - val_loss: 1.6702 - val_accuracy: 0.4296 - lr: 0.0100\n",
            "Epoch 2/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 1.0965 - accuracy: 0.6102 - val_loss: 1.1094 - val_accuracy: 0.6352 - lr: 0.0100\n",
            "Epoch 3/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.9199 - accuracy: 0.6791 - val_loss: 1.0632 - val_accuracy: 0.6570 - lr: 0.0100\n",
            "Epoch 4/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7898 - accuracy: 0.7269 - val_loss: 0.9471 - val_accuracy: 0.6836 - lr: 0.0100\n",
            "Epoch 5/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7248 - accuracy: 0.7514 - val_loss: 0.7249 - val_accuracy: 0.7531 - lr: 0.0100\n",
            "Epoch 6/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6722 - accuracy: 0.7701 - val_loss: 0.7814 - val_accuracy: 0.7356 - lr: 0.0100\n",
            "Epoch 7/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6270 - accuracy: 0.7871 - val_loss: 0.6556 - val_accuracy: 0.7918 - lr: 0.0100\n",
            "Epoch 8/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.5886 - accuracy: 0.8029 - val_loss: 0.6710 - val_accuracy: 0.7795 - lr: 0.0100\n",
            "Epoch 9/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5597 - accuracy: 0.8115 - val_loss: 0.5332 - val_accuracy: 0.8252 - lr: 0.0100\n",
            "Epoch 10/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.5396 - accuracy: 0.8194 - val_loss: 0.5101 - val_accuracy: 0.8292 - lr: 0.0100\n",
            "Epoch 11/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5105 - accuracy: 0.8272 - val_loss: 0.5139 - val_accuracy: 0.8369 - lr: 0.0100\n",
            "Epoch 12/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4752 - accuracy: 0.8403 - val_loss: 0.4329 - val_accuracy: 0.8567 - lr: 0.0100\n",
            "Epoch 13/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4603 - accuracy: 0.8445 - val_loss: 0.5144 - val_accuracy: 0.8416 - lr: 0.0100\n",
            "Epoch 14/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4908 - accuracy: 0.8354 - val_loss: 0.4873 - val_accuracy: 0.8429 - lr: 0.0100\n",
            "Epoch 15/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4373 - accuracy: 0.8526 - val_loss: 0.4281 - val_accuracy: 0.8648 - lr: 0.0100\n",
            "Epoch 16/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4053 - accuracy: 0.8651 - val_loss: 0.4684 - val_accuracy: 0.8546 - lr: 0.0100\n",
            "Epoch 17/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.3898 - accuracy: 0.8705 - val_loss: 0.3830 - val_accuracy: 0.8766 - lr: 0.0100\n",
            "Epoch 18/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.3788 - accuracy: 0.8709 - val_loss: 0.4384 - val_accuracy: 0.8621 - lr: 0.0100\n",
            "Epoch 19/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.3716 - accuracy: 0.8748 - val_loss: 0.4478 - val_accuracy: 0.8532 - lr: 0.0100\n",
            "Epoch 20/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.3732 - accuracy: 0.8757 - val_loss: 0.4279 - val_accuracy: 0.8709 - lr: 0.0100\n",
            "Epoch 21/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.3426 - accuracy: 0.8845 - val_loss: 0.5044 - val_accuracy: 0.8567 - lr: 0.0100\n",
            "Epoch 22/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3324 - accuracy: 0.8885 - val_loss: 0.4176 - val_accuracy: 0.8741 - lr: 0.0100\n",
            "Epoch 23/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2483 - accuracy: 0.9146 - val_loss: 0.3244 - val_accuracy: 0.8973 - lr: 0.0020\n",
            "Epoch 24/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2174 - accuracy: 0.9255 - val_loss: 0.3072 - val_accuracy: 0.9054 - lr: 0.0020\n",
            "Epoch 25/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2086 - accuracy: 0.9290 - val_loss: 0.3227 - val_accuracy: 0.9015 - lr: 0.0020\n",
            "Epoch 26/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1972 - accuracy: 0.9313 - val_loss: 0.2978 - val_accuracy: 0.9091 - lr: 0.0020\n",
            "Epoch 27/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1894 - accuracy: 0.9353 - val_loss: 0.3104 - val_accuracy: 0.9057 - lr: 0.0020\n",
            "Epoch 28/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1824 - accuracy: 0.9364 - val_loss: 0.2933 - val_accuracy: 0.9115 - lr: 0.0020\n",
            "Epoch 29/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1750 - accuracy: 0.9399 - val_loss: 0.3029 - val_accuracy: 0.9087 - lr: 0.0020\n",
            "Epoch 30/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.1699 - accuracy: 0.9419 - val_loss: 0.2998 - val_accuracy: 0.9125 - lr: 0.0020\n",
            "Epoch 31/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1685 - accuracy: 0.9415 - val_loss: 0.3122 - val_accuracy: 0.9079 - lr: 0.0020\n",
            "Epoch 32/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1606 - accuracy: 0.9446 - val_loss: 0.3005 - val_accuracy: 0.9114 - lr: 0.0020\n",
            "Epoch 33/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.1558 - accuracy: 0.9461 - val_loss: 0.3125 - val_accuracy: 0.9094 - lr: 0.0020\n",
            "Epoch 34/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.2935 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 35/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1390 - accuracy: 0.9522 - val_loss: 0.2939 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 36/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1311 - accuracy: 0.9545 - val_loss: 0.2988 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 37/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1328 - accuracy: 0.9527 - val_loss: 0.2929 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 38/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 0.2895 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 39/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1255 - accuracy: 0.9566 - val_loss: 0.3048 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 40/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1228 - accuracy: 0.9565 - val_loss: 0.3020 - val_accuracy: 0.9143 - lr: 0.0010\n",
            "Epoch 41/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1224 - accuracy: 0.9565 - val_loss: 0.3053 - val_accuracy: 0.9153 - lr: 0.0010\n",
            "Epoch 42/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.1239 - accuracy: 0.9561 - val_loss: 0.3056 - val_accuracy: 0.9164 - lr: 0.0010\n",
            "Epoch 43/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1161 - accuracy: 0.9603 - val_loss: 0.2975 - val_accuracy: 0.9159 - lr: 0.0010\n",
            "Epoch 44/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1161 - accuracy: 0.9591 - val_loss: 0.3047 - val_accuracy: 0.9146 - lr: 0.0010\n",
            "Epoch 45/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1142 - accuracy: 0.9597 - val_loss: 0.3080 - val_accuracy: 0.9150 - lr: 0.0010\n",
            "Epoch 46/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.1161 - accuracy: 0.9588 - val_loss: 0.3044 - val_accuracy: 0.9149 - lr: 0.0010\n",
            "Epoch 47/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1096 - accuracy: 0.9615 - val_loss: 0.3165 - val_accuracy: 0.9139 - lr: 0.0010\n",
            "Epoch 48/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1105 - accuracy: 0.9617 - val_loss: 0.3111 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 49/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1071 - accuracy: 0.9617 - val_loss: 0.3077 - val_accuracy: 0.9149 - lr: 0.0010\n",
            "Epoch 50/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1028 - accuracy: 0.9631 - val_loss: 0.3251 - val_accuracy: 0.9134 - lr: 0.0010\n",
            "Epoch 51/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1036 - accuracy: 0.9633 - val_loss: 0.3149 - val_accuracy: 0.9165 - lr: 0.0010\n",
            "Epoch 52/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0997 - accuracy: 0.9646 - val_loss: 0.3161 - val_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 53/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1029 - accuracy: 0.9638 - val_loss: 0.3091 - val_accuracy: 0.9185 - lr: 0.0010\n",
            "Epoch 54/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.1002 - accuracy: 0.9646 - val_loss: 0.3125 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 55/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 0.3197 - val_accuracy: 0.9165 - lr: 0.0010\n",
            "Epoch 56/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.0954 - accuracy: 0.9668 - val_loss: 0.3312 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 57/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0948 - accuracy: 0.9663 - val_loss: 0.3265 - val_accuracy: 0.9145 - lr: 0.0010\n",
            "Epoch 58/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0954 - accuracy: 0.9666 - val_loss: 0.3138 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 59/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0904 - accuracy: 0.9677 - val_loss: 0.3137 - val_accuracy: 0.9188 - lr: 0.0010\n",
            "Epoch 60/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0919 - accuracy: 0.9672 - val_loss: 0.3221 - val_accuracy: 0.9149 - lr: 0.0010\n",
            "Epoch 61/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0882 - accuracy: 0.9692 - val_loss: 0.3241 - val_accuracy: 0.9165 - lr: 0.0010\n",
            "Epoch 62/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.0889 - accuracy: 0.9682 - val_loss: 0.3455 - val_accuracy: 0.9124 - lr: 0.0010\n",
            "Epoch 63/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0908 - accuracy: 0.9679 - val_loss: 0.3220 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 64/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0846 - accuracy: 0.9701 - val_loss: 0.3206 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 65/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0848 - accuracy: 0.9704 - val_loss: 0.3232 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 66/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.0839 - accuracy: 0.9708 - val_loss: 0.3401 - val_accuracy: 0.9143 - lr: 0.0010\n",
            "Epoch 67/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0836 - accuracy: 0.9707 - val_loss: 0.3251 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 68/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 0.3252 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 69/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0820 - accuracy: 0.9710 - val_loss: 0.3282 - val_accuracy: 0.9176 - lr: 0.0010\n",
            "Epoch 70/120\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.0751 - accuracy: 0.9738 - val_loss: 0.3319 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 71/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0800 - accuracy: 0.9712 - val_loss: 0.3429 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 72/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0787 - accuracy: 0.9729 - val_loss: 0.3302 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 73/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.3398 - val_accuracy: 0.9161 - lr: 0.0010\n",
            "Epoch 74/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 0.3266 - val_accuracy: 0.9201 - lr: 0.0010\n",
            "Epoch 75/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0739 - accuracy: 0.9735 - val_loss: 0.3313 - val_accuracy: 0.9208 - lr: 0.0010\n",
            "Epoch 76/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.3357 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 77/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0734 - accuracy: 0.9747 - val_loss: 0.3564 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 78/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0689 - accuracy: 0.9759 - val_loss: 0.3353 - val_accuracy: 0.9200 - lr: 0.0010\n",
            "Epoch 79/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0715 - accuracy: 0.9754 - val_loss: 0.3445 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 80/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0737 - accuracy: 0.9746 - val_loss: 0.3386 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 81/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.3406 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 82/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0713 - accuracy: 0.9757 - val_loss: 0.3366 - val_accuracy: 0.9215 - lr: 0.0010\n",
            "Epoch 83/120\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.0704 - accuracy: 0.9754 - val_loss: 0.3335 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 84/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0699 - accuracy: 0.9756 - val_loss: 0.3427 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 85/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0662 - accuracy: 0.9768 - val_loss: 0.3456 - val_accuracy: 0.9200 - lr: 0.0010\n",
            "Epoch 86/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0654 - accuracy: 0.9766 - val_loss: 0.3438 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 87/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0650 - accuracy: 0.9777 - val_loss: 0.3444 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 88/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0611 - accuracy: 0.9780 - val_loss: 0.3477 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 89/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0663 - accuracy: 0.9769 - val_loss: 0.3520 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 90/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0620 - accuracy: 0.9784 - val_loss: 0.3595 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 91/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0660 - accuracy: 0.9771 - val_loss: 0.3485 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 92/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0640 - accuracy: 0.9774 - val_loss: 0.3551 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 93/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.3410 - val_accuracy: 0.9199 - lr: 0.0010\n",
            "Epoch 94/120\n",
            "781/781 [==============================] - 36s 45ms/step - loss: 0.0608 - accuracy: 0.9790 - val_loss: 0.3480 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 95/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 0.3464 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 96/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0603 - accuracy: 0.9789 - val_loss: 0.3474 - val_accuracy: 0.9200 - lr: 0.0010\n",
            "Epoch 97/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0585 - accuracy: 0.9799 - val_loss: 0.3648 - val_accuracy: 0.9177 - lr: 0.0010\n",
            "Epoch 98/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0595 - accuracy: 0.9788 - val_loss: 0.3554 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 99/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0593 - accuracy: 0.9790 - val_loss: 0.3617 - val_accuracy: 0.9176 - lr: 0.0010\n",
            "Epoch 100/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.3522 - val_accuracy: 0.9184 - lr: 0.0010\n",
            "Epoch 101/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0588 - accuracy: 0.9795 - val_loss: 0.3442 - val_accuracy: 0.9228 - lr: 0.0010\n",
            "Epoch 102/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 0.3611 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 103/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.3597 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 104/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 0.3603 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 105/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0549 - accuracy: 0.9807 - val_loss: 0.3635 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 106/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.3664 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 107/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0554 - accuracy: 0.9807 - val_loss: 0.3772 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 108/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 0.3637 - val_accuracy: 0.9192 - lr: 0.0010\n",
            "Epoch 109/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.3724 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 110/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.3553 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 111/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.3686 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 112/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0508 - accuracy: 0.9821 - val_loss: 0.3551 - val_accuracy: 0.9180 - lr: 0.0010\n",
            "Epoch 113/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 0.3532 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 114/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.3802 - val_accuracy: 0.9159 - lr: 0.0010\n",
            "Epoch 115/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0530 - accuracy: 0.9809 - val_loss: 0.3467 - val_accuracy: 0.9216 - lr: 0.0010\n",
            "Epoch 116/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.3572 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 117/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0483 - accuracy: 0.9835 - val_loss: 0.3810 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 118/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.3614 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 119/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.3632 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 120/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0468 - accuracy: 0.9835 - val_loss: 0.3728 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Test loss: 0.372806578874588\n",
            "Test accuracy: 0.9194999933242798\n"
          ]
        }
      ]
    }
  ]
}